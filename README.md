# Handwritten Digit Recognition System

A production-oriented research project that benchmarks classical machine learning, deep learning, and attention-driven architectures on the MNIST handwritten digits corpus while delivering deployable artifacts, analytical insights, and optimization recipes for multiple inference targets.

## ğŸ“‹ Overview

- **Scope**: End-to-end digit recognition covering raw data profiling, feature engineering, supervised learning, transfer learning, and deployment-ready compression.
- **Deliverables**: Executable notebook, curated model zoo, enriched feature datasets, augmentation pipelines, comparative reports, and optimization playbooks.
- **Objective**: Provide a reusable reference stack that balances accuracy, latency, and footprint for scenarios ranging from academic experimentation to edge deployment.

## ğŸš€ Highlights

- **11+ feature families** stitched into comprehensive 1,511-dimensional descriptors alongside PCA and LDA reductions for classical models.
- **Model portfolio** spanning Logistic Regression, SVM, Random Forest, XGBoost, KNN, Decision Trees, dense neural nets, CNNs, CRNNs, CBAM/SE/self-attention variants, MobileNetV2 transfer learning, and vision transformers.
- **Ensemble and optimization tooling** including stacking, soft voting, pruning, quantization, active learning, adversarial training, and Git LFS-backed checkpoints.
- **Advanced analytics** capturing pixel intensity statistics, confusable class clusters, augmentation impact (5Ã— expansion), and actionable deployment recommendations.

## ğŸ§± Repository Layout

```
.
â”œâ”€â”€ ATTENTION MECHANISM_MODELS/           # CBAM, SE-block, self-attention, ViT checkpoints + histories
â”œâ”€â”€ AUGMENTATION MODEL/                   # Serialized augmentation pipeline for reproducible synthetic sampling
â”œâ”€â”€ Basic_Neural_Network_Models/          # Torch-based dense baselines (.pth)
â”œâ”€â”€ CNN_MODEL_CSV_FILE/                   # Advanced CNN weights and training metrics (.pth/.csv/.pkl)
â”œâ”€â”€ CRNN_MODEL_MULTI_DIGIT_RECOGNITION/   # Sequence-aware CRNN models for multi-digit inference
â”œâ”€â”€ Classical_ML_Models/                  # Pickled scikit-learn pipelines and deployment summaries
â”œâ”€â”€ Datasets_of_Feature_Engineering/      # CSV exports of engineered feature spaces (HOG, LBP, PCA, LDA, etc.)
â”œâ”€â”€ ENSEMBEL_METHODS_MODELS/              # Stacking/soft-voting ensembles with performance snapshots
â”œâ”€â”€ Generative_Models/                    # DCGAN, CGAN, WGAN, VAE, and style transfer generators + metrics
â”œâ”€â”€ Preprocessed_Training_&_Test_Dataset/ # Cached NumPy arrays and pipeline configs for fast reloads
â”œâ”€â”€ Transfer_Learning_Models/             # Fine-tuned MobileNetV2 (Keras/TFLite) and learning histories
â”œâ”€â”€ Complete_Data_Analysis_Report.md      # 70K-sample exploratory analytics and statistical deep dives
â”œâ”€â”€ Challenges_and_Solutions_Report.md    # Engineering retrospective on bottlenecks and mitigations
â”œâ”€â”€ Model_Comparison_Report.md            # Accuracy/latency/size trade-off matrix across approaches
â”œâ”€â”€ PRCP-1002-Handwritten_Digits_Recognition_Final_File3ipynb (1).ipynb
â””â”€â”€ PRCP-1002-Handwritten_Digits_Recognition_Final_File3ipynb.json
```

## ğŸ› ï¸ Environment Setup

1. **Clone and enter the workspace**
   ```bash
   git clone https://github.com/Roy12233444/PRCP-1002-Handwritten-Digits-Recognition.git
   cd PRCP-1002-Handwritten-Digits-Recognition
   ```
2. **Create an isolated environment** (Python â‰¥3.9 recommended)
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Linux/macOS: source venv/bin/activate
   ```
3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
   If the requirements file is unavailable, install the core stack:
   ```bash
   pip install numpy pandas matplotlib seaborn scikit-learn tensorflow torch torchvision opencv-python xgboost albumentations
   ```
4. **Enable Git LFS** for large model binaries
   ```bash
   git lfs install
   git lfs pull
   ```

## ğŸ“š Working with the Notebook

1. **Launch Jupyter**
   ```bash
   jupyter notebook "PRCP-1002-Handwritten_Digits_Recognition_Final_File3ipynb (1).ipynb"
   ```
2. **Execution flow**
   1. Global configuration and smart NPZ caching
   2. Exploratory analysis and visualization dashboards
   3. Feature engineering pipelines (classical + deep)
   4. Training suites for classical ML, CNNs, attention modules, CRNNs, and transfer learning
   5. Ensemble orchestration and comparative evaluation
   6. Compression experiments (pruning, quantization, TFLite export)
3. **Runtime tips**
   - Set `RANDOM_STATE` consistently to reproduce benchmark tables
   - Use provided `pipeline_config.json` for deterministic preprocessing stages
   - Switch model sections on/off via notebook flags to conserve compute

## ğŸ”„ Data & Preprocessing Pipeline

- **Source dataset**: MNIST (70K grayscale 28Ã—28 digits, balanced across classes).
- **Caching**: NPZ-based loader reduces repeated I/O by ~30%.
- **Normalization**: Pixels scaled to `[0,1]`, optional contrast enhancement.
- **Augmentation**: Rotation (Â±15Â°), translation (Â±10%), scaling (0.9â€“1.1), shearing, elastic deformation, adaptive histogram equalization, Gaussian noise, Cutout.
- **Feature Engineering**: HOG, LBP, Hu moments, gradient, morphological, Fourier, Wavelet, Zernike, statistical descriptors; PCA (95% variance) and LDA (9 dims) variants provided via CSV exports.

## ğŸ§  Model Landscape & Benchmarks

| Family | Representative Artifact | Accuracy* | Footprint | Notes |
|---|---|---|---|---|
| Classical ML | `Classical_ML_Models/random_forest_model.pkl` | 94â€“95% | 20â€¯MB | Uses engineered features + PCA pipeline |
| CNN Baseline | `CNN_MODEL_CSV_FILE/advanced_cnn_chunked_20250706_090829.pth` | 98â€“99% | 5.45â€¯MB | Adam optimizer, BN, dropout, early stopping |
| Attention CNN (CBAM) | `ATTENTION MECHANISM_MODELS/attention_model_cnn_cbam.h5` | 98% | 1.97â€¯MB | Channel-spatial attention boosts confusable digits |
| Vision Transformer | `ATTENTION MECHANISM_MODELS/attention_model_vision_transformer.h5` | 97â€“98% | 4.3â€¯MB | Patch embedding + multi-head self-attention |
| CRNN | `CRNN_MODEL_MULTI_DIGIT_RECOGNITION/crnn_model.h5` | 97% | 3.71â€¯MB | Handles sequential multi-digit inputs |
| Transfer Learning | `Transfer_Learning_Models/transfer_learning_mobilenetv2_finetuned_mnist.tflite` | 97% | 2.55â€¯MB | Quantized MobileNetV2 for edge devices |
| Stacking Ensemble | `ENSEMBEL_METHODS_MODELS/stacking_ensemble.h5` | 98.5â€“99.2% | 2.68â€¯MB | Meta-learner over CNN + dense + specialty models |
| Quantized CNN | `Transfer_Learning_Models/best_transfer_model.h5` (pre-quant) | 94.8% | 230â€¯KB (TFLite) | 73% size reduction with minimal accuracy loss |

*Accuracy ranges derive from `Model_Comparison_Report.md` and notebook evaluations; rerun cells to reproduce figures under your hardware constraints.

## ğŸ“ˆ Evaluation & Diagnostics

- **Confusion analysis**: Top confusions (3â†”8, 4â†”9, 6â†”8) visualized with per-class metrics in the notebook.
- **Dimensionality insights**: PCA retains 95% variance within 150â€“200 components; t-SNE plots highlight cluster separability.
- **Quality metrics**: Edge density, brightness, contrast, and sparsity tracked per digit to inform augmentation focus.
- **Reports**: Deep dives available in `Complete_Data_Analysis_Report.md`, `Challenges_and_Solutions_Report.md`, and `Model_Comparison_Report.md`.

## ğŸš¢ Deployment Playbook

1. **Baseline export**: Save best Keras/Torch weights during training checkpoints.
2. **Compression**: Apply pruning (80% sparsity) followed by post-training quantization for 4Ã—â€“5Ã— footprint reduction with <5% accuracy drop.
3. **Edge delivery**: Use bundled `.tflite` artifacts; integrate with TensorFlow Lite `Interpreter` for <10â€¯ms inference on mobile-class CPUs.
4. **Monitoring**: Track confusable pairs and drift via periodic evaluation on augmented validation sets.

## â™»ï¸ Reproducibility Checklist

1. Activate the virtual environment and install dependencies.
2. Pull LFS artifacts to ensure models and datasets are available locally.
3. Execute notebook sections sequentially, seeding `numpy`, `tensorflow`, and `torch` with the same `RANDOM_STATE`.
4. Use cached NumPy datasets and feature CSVs for deterministic classical model training.
5. Record checkpoints and evaluation metrics for comparison against the supplied reports.

## ğŸ¤ Contributing

- **Issues**: Use GitHub Issues for bug reports, feature requests, or clarifications.
- **Pull Requests**: Provide reproducible benchmarks and mention affected artifacts (models, datasets, reports).
- **Experiments**: New architectures should include validation metrics and updated analysis snapshots.

## ğŸ“„ License & Attribution

- **License**: MIT â€” consult `LICENSE` for terms.
- **Dataset**: MNIST by Yann LeCun et al. (public domain). Please cite appropriately in derivative work.
